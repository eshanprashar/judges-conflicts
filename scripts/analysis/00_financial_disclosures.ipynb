{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env: wang-ml-py3.11\n",
    "# Pending: Adding poetry environment and dependencies\n",
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "# import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the working directory\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "fin_disc_data_dir = os.path.join(grandparent_dir, 'data/financial_disc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load data from the financial disclosure directory\n",
    "\n",
    "def load_data(data_dir):\n",
    "    '''\n",
    "    This function is not memory efficient, but for <100 csv files, should work fine\n",
    "    For example: this approach will have to be modified for docket/PACER data\n",
    "    '''\n",
    "    all_files = glob.glob(data_dir + \"/*.csv\")\n",
    "    print(f\"Found {len(all_files)} files in the directory\")\n",
    "    li = []\n",
    "    for filename in all_files:\n",
    "        try:\n",
    "            df = pd.read_csv(filename, index_col=None, header=0)\n",
    "            li.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {filename}: {e}\")\n",
    "    return pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54 files in the directory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (9,13,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (15,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (13,14,15,16,32,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (9,13,14,15,16,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n",
      "/var/folders/54/mhs5zkcs6zb1_y58hd7pczjc0000gn/T/ipykernel_34070/1404753717.py:13: DtypeWarning: Columns (32) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=None, header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2019751 entries, 0 to 2019750\n",
      "Data columns (total 52 columns):\n",
      " #   Column                               Dtype  \n",
      "---  ------                               -----  \n",
      " 0   person_id                            int64  \n",
      " 1   person_url                           object \n",
      " 2   filepath                             object \n",
      " 3   disclosure_year                      int64  \n",
      " 4   notes                                object \n",
      " 5   date_created                         object \n",
      " 6   date_modified                        object \n",
      " 7   type                                 object \n",
      " 8   agreement_id                         float64\n",
      " 9   agree_date_raw                       object \n",
      " 10  parties_and_terms                    object \n",
      " 11  agree_redacted                       object \n",
      " 12  gift_id                              float64\n",
      " 13  gift_source                          object \n",
      " 14  gift_description                     object \n",
      " 15  gift_value                           object \n",
      " 16  gift_redacted                        object \n",
      " 17  investment_id                        float64\n",
      " 18  inv_description                      object \n",
      " 19  inv_redacted                         object \n",
      " 20  income_during_reporting_period_code  object \n",
      " 21  income_during_reporting_period_type  object \n",
      " 22  gross_value_code                     object \n",
      " 23  gross_value_method                   object \n",
      " 24  transaction_during_reporting_period  object \n",
      " 25  transaction_date_raw                 object \n",
      " 26  transaction_date                     object \n",
      " 27  transaction_value_code               object \n",
      " 28  transaction_gain_code                object \n",
      " 29  transaction_partner                  object \n",
      " 30  inv_has_inferred_values              object \n",
      " 31  non_investment_income_id             float64\n",
      " 32  non_inv_date_raw                     object \n",
      " 33  non_inv_source_type                  object \n",
      " 34  non_inv_income_amount                object \n",
      " 35  non_inv_redacted                     object \n",
      " 36  position_id                          float64\n",
      " 37  position                             object \n",
      " 38  organization_name                    object \n",
      " 39  date_raw_position                    float64\n",
      " 40  position_redacted                    object \n",
      " 41  reimbursement_id                     float64\n",
      " 42  reimb_source                         object \n",
      " 43  date_raw_reimb                       float64\n",
      " 44  reimb_location                       object \n",
      " 45  reimb_purpose                        float64\n",
      " 46  items_paid_or_provided               object \n",
      " 47  reimb_redacted                       object \n",
      " 48  spouse_income_id                     float64\n",
      " 49  sp_inc_source_type                   object \n",
      " 50  sp_inc_date_raw                      object \n",
      " 51  sp_inc_redacted                      object \n",
      "dtypes: float64(10), int64(2), object(40)\n",
      "memory usage: 801.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loading files from the financial disclosure directory\n",
    "df_fin_disc = load_data(fin_disc_data_dir)\n",
    "\n",
    "# Examine the data\n",
    "df_fin_disc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data to a parquet file for future use\n",
    "# df_fin_disc.to_parquet(os.path.join(grandparent_dir, 'data/financial_disc/financial_disc.parquet'), index=False)\n",
    "# print(\"Data saved to parquet file in directory: {fin_disc_data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique persons in the dataset: 3349\n",
      "Number of unique disclosures in the dataset: 30436\n",
      "Number of unique investments in the dataset: 1901720\n"
     ]
    }
   ],
   "source": [
    "# Let us see how many unique persons, disclosures and investments are there in the dataset\n",
    "print(f\"Number of unique persons in the dataset: {df_fin_disc['person_id'].nunique()}\")\n",
    "print(f\"Number of unique disclosures in the dataset: {df_fin_disc['filepath'].nunique()}\")\n",
    "print(f\"Number of unique investments in the dataset: {df_fin_disc['investment_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 37050 entries, 40 to 2019718\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   position_id        37050 non-null  float64\n",
      " 1   position           36823 non-null  object \n",
      " 2   disclosure_year    37050 non-null  int64  \n",
      " 3   organization_name  36282 non-null  object \n",
      " 4   date_created       37050 non-null  object \n",
      " 5   date_modified      37050 non-null  object \n",
      " 6   position_redacted  37050 non-null  object \n",
      " 7   person_id          37050 non-null  int64  \n",
      " 8   filepath           37050 non-null  object \n",
      " 9   notes              24635 non-null  object \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe for just positions\n",
    "df_positions = df_fin_disc[df_fin_disc['type'] == 'position']\n",
    "columns_to_keep = ['position_id','position','disclosure_year', 'organization_name','date_created','date_modified','position_redacted','person_id', 'filepath', 'notes']\n",
    "df_positions = df_positions[columns_to_keep]\n",
    "\n",
    "# Examine the dataframe\n",
    "df_positions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique people: 2553\n",
      "Number of unique positions: 37050\n"
     ]
    }
   ],
   "source": [
    "# Let us see how many unique people and positions exist in the dataset\n",
    "print(f\"Number of unique people: {df_positions['person_id'].nunique()}\")\n",
    "print(f\"Number of unique positions: {df_positions['position_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51281 entries, 0 to 51280\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   person_id               51281 non-null  int64  \n",
      " 1   name_first              51281 non-null  object \n",
      " 2   name_middle             43300 non-null  object \n",
      " 3   name_last               51281 non-null  object \n",
      " 4   political_affiliations  35456 non-null  object \n",
      " 5   race                    33919 non-null  object \n",
      " 6   position_url            51281 non-null  object \n",
      " 7   position_type           30056 non-null  object \n",
      " 8   job_title               21225 non-null  object \n",
      " 9   sector                  6764 non-null   float64\n",
      " 10  organization            13248 non-null  object \n",
      " 11  date_nominated          4274 non-null   object \n",
      " 12  date_start              50412 non-null  object \n",
      " 13  date_termination        42457 non-null  object \n",
      " 14  court_resource_url      22174 non-null  object \n",
      " 15  court_id                22174 non-null  object \n",
      " 16  court_short_name        22174 non-null  object \n",
      " 17  court_full_name         22174 non-null  object \n",
      " 18  court_url               20593 non-null  object \n",
      " 19  position                51281 non-null  object \n",
      " 20  judge_flag              51281 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(18)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Importing the persons and positions data from persons_positions.csv\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "grandparent_dir = os.path.dirname(parent_dir)\n",
    "persons_positions_dir = os.path.join(grandparent_dir, 'data/persons_positions')\n",
    "df_persons_positions = pd.read_csv(os.path.join(persons_positions_dir, 'persons_positions_modified.csv'))\n",
    "\n",
    "# Examine the data\n",
    "df_persons_positions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 216862 entries, 0 to 216861\n",
      "Data columns (total 30 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   person_id               216862 non-null  int64  \n",
      " 1   name_first              216862 non-null  object \n",
      " 2   name_middle             196183 non-null  object \n",
      " 3   name_last               216862 non-null  object \n",
      " 4   political_affiliations  189429 non-null  object \n",
      " 5   race                    188046 non-null  object \n",
      " 6   position_url            216862 non-null  object \n",
      " 7   position_type           73842 non-null   object \n",
      " 8   job_title               143020 non-null  object \n",
      " 9   sector                  7362 non-null    float64\n",
      " 10  organization            85160 non-null   object \n",
      " 11  date_nominated          30881 non-null   object \n",
      " 12  date_start              215876 non-null  object \n",
      " 13  date_termination        163980 non-null  object \n",
      " 14  court_resource_url      63235 non-null   object \n",
      " 15  court_id                63235 non-null   object \n",
      " 16  court_short_name        63235 non-null   object \n",
      " 17  court_full_name         63235 non-null   object \n",
      " 18  court_url               61644 non-null   object \n",
      " 19  position_x              216862 non-null  object \n",
      " 20  judge_flag              216862 non-null  int64  \n",
      " 21  position_id             176665 non-null  float64\n",
      " 22  position_y              175292 non-null  object \n",
      " 23  disclosure_year         176665 non-null  float64\n",
      " 24  organization_name       172910 non-null  object \n",
      " 25  date_created            176665 non-null  object \n",
      " 26  date_modified           176665 non-null  object \n",
      " 27  position_redacted       176665 non-null  object \n",
      " 28  filepath                176665 non-null  object \n",
      " 29  notes                   116188 non-null  object \n",
      "dtypes: float64(3), int64(2), object(25)\n",
      "memory usage: 49.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Join the two dataframes on person_id using outer join\n",
    "df_persons_positions = df_persons_positions.merge(df_positions, on='person_id', how='outer')\n",
    "df_persons_positions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examing csv files in the directory\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (wang-ml-py3.11)",
   "language": "python",
   "name": "wang-ml-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
